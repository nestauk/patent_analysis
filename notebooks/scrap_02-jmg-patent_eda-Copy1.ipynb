{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patent eda\n",
    "\n",
    "This is an exploratory analysis of the patent data. \n",
    "\n",
    "Some questions:\n",
    "\n",
    "* What are the variables in the data?\n",
    "* What are the missing and present values?\n",
    "* What do the data capture *legally*?\n",
    "* What will be the most interesting transformations to carry out in this data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run notebook_preamble.ipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = pd.read_csv('../data/raw/18_6_2019_patent_apps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('|name|type|observations|')\n",
    "print('|----|----|----|')\n",
    "\n",
    "for c in pat.columns:\n",
    "    \n",
    "    print(f'|{c}|{type(pat[c].iloc[0])}|   |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in pat.columns:\n",
    "    \n",
    "    print(c)\n",
    "    print('=====')\n",
    "    \n",
    "    var = pat[c].dropna()\n",
    "    \n",
    "    print(type(var.iloc[0]))\n",
    "    print(var.iloc[0])\n",
    "    \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in pat.columns:\n",
    "    \n",
    "    print(c)\n",
    "    print('=====')\n",
    "    \n",
    "    var = pat[c].dropna()\n",
    "    \n",
    "    print(type(var.iloc[0]))\n",
    "    print(var.iloc[0])\n",
    "    \n",
    "    print('\\n')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some questions to check:\n",
    "\n",
    "* How many unique ids are there?\n",
    "* Is it a many patents to one applicant table?\n",
    "* Or do we have lists of applicants where there is more than one?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some basic analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many patents are there in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(pat.appln_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look: only around 770k unique ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(set(pat.docdb_family_id))\n",
    "\n",
    "len(set(pat.docdb_family_id.dropna()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Less than 300,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what about people / organisations\n",
    "\n",
    "len(set(pat.psn_id.dropna()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More persons than patents, suggesting that each row represents one person. Let's check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pat.dropna(axis=0,\n",
    "#            subset=['docdb_family_id']).loc[pat['docdb_family_id'].duplicated()][['appln_id','psn_name','docdb_family_id','appln_abstract']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#focus on patents with ids\n",
    "\n",
    "pat.sort_values('appln_id')[['appln_id','person_name','docdb_family_id','appln_abstract','person_address',\n",
    "                             'invt_seq_nr','applt_seq_nr','appln_auth']].head(n=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some observations:\n",
    "\n",
    "* Each row captures a bit of information - the name and address of an inventor or applicant, the abstract etc...\n",
    "* Some of the missing inventors / applicants must be based outside of GB\n",
    "\n",
    "Shall we create a df where every row is a patent application?\n",
    "\n",
    "We would then have:\n",
    "\n",
    "* Abstract\n",
    "* Technical information (technology area, ipc code, nace code etc.)\n",
    "* Patent family\n",
    "* Application and publication year\n",
    "* Whether it has been granted or not\n",
    "* Authority (can we check repeated patents?)\n",
    "* Information about inventor\n",
    "* Information about the applicant\n",
    "* Information about the inventor\n",
    "\n",
    "For each variable we should group over application ids and create a list of the other variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organise the patent data more sensibly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# For each column, group and aggregate\n",
    "\n",
    "pat_gr = []\n",
    "\n",
    "for column in pat.columns:\n",
    "    \n",
    "    #print(column)\n",
    "    \n",
    "    p = pat.copy()\n",
    "    \n",
    "    #Drop nas for the column:\n",
    "    \n",
    "    p = p.dropna(axis=0,subset=[column])\n",
    "    \n",
    "    #We create a list of values. Later on we will extract values when the length of the list is always zero or 1\n",
    "    \n",
    "    group = p.groupby('appln_id')[column].apply(lambda x: list(x))\n",
    "    \n",
    "    pat_gr.append(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_grouped = pd.concat(pat_gr,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps: \n",
    "\n",
    "* Convert non list variables\n",
    "* Remove redundant fields\n",
    "* Do EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract from list those fields that only have one value:\n",
    "\n",
    "pat_grouped_2 = pat_grouped.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each column\n",
    "for c in pat_grouped.columns:\n",
    "    \n",
    "    #If a column has all values with the same length, extract that value from the list (it is not a list)\n",
    "    n_vals = len(set([len(x) for x in pat_grouped[c].dropna()]))\n",
    "    \n",
    "    print(n_vals)\n",
    "    \n",
    "    if n_vals==1:\n",
    "        pat_grouped_2[c]= pat_grouped[c].apply(lambda x: x[0] if pd.isnull(x)==False else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in pat_grouped_2.columns:\n",
    "    \n",
    "    print(c)\n",
    "    print('=====')\n",
    "    \n",
    "    var = pat_grouped_2[c].dropna()\n",
    "    \n",
    "    try:\n",
    "        print(type(var.iloc[0]))\n",
    "        print(var.iloc[0])\n",
    "    except:\n",
    "        print('all missing')\n",
    "    \n",
    "    print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pat_grouped_2.to_csv(f'../data/interim/{today_str}_patent_grouped.csv',compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat.appln_auth.value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are these duplicated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat.appln_filing_year.value_counts().loc[np.arange(2005,2019)].plot.bar(color='blue',title='Patents per year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat.appln_kind.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the W means an international application under the cooperation treaty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.ProfileReport(pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
